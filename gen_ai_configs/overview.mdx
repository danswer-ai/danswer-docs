---
title: Overview
description: 'Overview of the Generative AI functionality in Danswer'
---

## What are Generative AI (LLM) models used for?
The Large Language Models are used to interpret the contents from the most relevant documents retrieved via Search.
These models extract out the useful knowledge from your documents and generates the **AI Answer**.

## What is the default LLM?
By default, Danswer uses `GPT-3.5-Turbo` from OpenAI. This is the most accessible model/hosting service since it does
not require any access approval process like `GPT-4` or `Llama2` variants.
OpenAI also hosts the models behind an API which makes it easy to use and much more cost efficient than hosting a model
yourself on dedicated hardware.

## Why would you want to use a different model
- Use a more powerful model despite higher cost (such as GPT-4)
- Use a hosting service with a different data retention policy
    - Currently OpenAI and Azure OpenAI retain data for 30 days for monitoring against misuse
- Host the model yourself for complete control and flexibility
    - The Gen AI is the only feature in Danswer that reaches out to third party controlled service
    - There are options (see below) to avoid this entirely but at the cost of performance
- Use a different model perhaps finetuned or better suited for a particular domain of interest

## What are the options
- Other OpenAI models such as `gpt-4` or `text-davinci-003`
- Azure OpenAI. The same models as OpenAI but via Azure Cloud for better security guarantees.
    - As of Aug 2023, requires [approval](https://customervoice.microsoft.com/Pages/ResponsePage.aspx?id=v4j5cvGGr0GRqy180BHbR7en2Ais5pxKtso_Pz4b1_xUOFA5Qk1UWDRBMjg0WFhPMkIzTzhKQ1dWNyQlQCN0PWcu)
- GPT4All and all compatible models.
    - This runs the compressed LLMs in memory within Danswer removing the dependency on an externally hosted model
    - This approach requires a beefy system or a significant sacrifice in performance.
- HuggingFace Hosted Inference API
    - Requires a `Pro` subscription.
    - HuggingFace does not store prompts/tokens but does store logs.
- Any LLM interfaced via REST API
    - Intended for self hosted models on-prem or in any cloud provider such as AWS, Azure, GCP, etc.
    - May require minor extension/rebuilding of Danswer containers to conform to the expected API for the model.

See the following sections for how to configure the different options.

As always, don't hesitate to reach out to the Danswer team if you have any questions or issues.